{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff8a741",
   "metadata": {},
   "source": [
    "## Average STC data across subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a423b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import mne\n",
    "from src.MovieEEGSourcePipeline.source import _load_epochs, make_forward, make_inverse_from_baseline\n",
    "\n",
    "\n",
    "DATA_DIR = Path(\"data/epochs\")\n",
    "SUBJECTS_DIR = Path(\"data\")\n",
    "FS_SUBJECT = \"fsaverage\"\n",
    "\n",
    "# Use an ico-4 source space (coarse; appropriate for Yeo-7 parcellation)\n",
    "FS_SRC_FNAME = SUBJECTS_DIR / FS_SUBJECT / \"bem\" / \"fsaverage-ico-4-src.fif\"\n",
    "FS_BEM_FNAME = SUBJECTS_DIR / FS_SUBJECT / \"bem\" / \"fsaverage-5120-5120-5120-bem-sol.fif\"\n",
    "\n",
    "\n",
    "def extract_stcs(\n",
    "    epochs: mne.Epochs,\n",
    "    inv: mne.minimum_norm.InverseOperator,\n",
    ") -> list[mne.SourceEstimate]:\n",
    "    stcs = mne.minimum_norm.apply_inverse_epochs(\n",
    "        epochs,\n",
    "        inverse_operator=inv,\n",
    "        method=\"eLORETA\",\n",
    "        lambda2=1.0 / 9.0,\n",
    "        pick_ori=\"normal\",     # explicit orientation choice\n",
    "        return_generator=False,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    return stcs\n",
    "\n",
    "\n",
    "def average_stcs(stcs: list[mne.SourceEstimate]) -> mne.SourceEstimate:\n",
    "    if len(stcs) == 0:\n",
    "        raise ValueError(\"No STCs to average.\")\n",
    "    # Average across epochs (time x vertices)\n",
    "    stcs_avg = np.mean([stc.data for stc in stcs], axis=0)\n",
    "\n",
    "    stc_mean = mne.SourceEstimate(\n",
    "        stcs_avg,\n",
    "        vertices=stcs[0].vertices,\n",
    "        tmin=stcs[0].tmin,\n",
    "        tstep=stcs[0].tstep,\n",
    "        subject=stcs[0].subject,\n",
    "    )\n",
    "    return stc_mean\n",
    "\n",
    "\n",
    "# Helpers\n",
    "def run_source_localisation(data_dir, fs_subject, fs_src_fname, fs_bem_fname):\n",
    "\n",
    "    # Pick a single example file to define channel set for forward model\n",
    "    example = next(data_dir.glob(\"*_city_l_epo.fif\"), None)\n",
    "    if example is None:\n",
    "        example = next(data_dir.glob(\"*_epo.fif\"), None)\n",
    "    if example is None:\n",
    "        raise FileNotFoundError(f\"No epoch files found in {data_dir} to build forward model.\")\n",
    "    fwd = make_forward(example, FS_SUBJECT=fs_subject, FS_SRC_FNAME=fs_src_fname, FS_BEM_FNAME=fs_bem_fname)\n",
    "\n",
    "    inv_cache = {}  # subject -> inverse operator built from baseline1\n",
    "\n",
    "    for epochs_path in sorted(data_dir.glob(\"*_epo.fif\")):\n",
    "        m = re.search(r\"^(\\d+)_([^_]+_[^_]+)_epo$\", epochs_path.stem)\n",
    "        if m is None:\n",
    "            continue\n",
    "        subject, film = m.groups()\n",
    "\n",
    "        epochs = _load_epochs(epochs_path)\n",
    "\n",
    "        out_dir = Path(\"data/stcs\")\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_path_stcs = out_dir / f\"{subject}_{film}_stcs.npz\"\n",
    "\n",
    "        if output_path_stcs.exists():\n",
    "            print(f\"STCs for {subject} {film} already exist, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Ensure we have an inverse per subject (from baseline1)\n",
    "        if subject not in inv_cache:\n",
    "            # pick baseline portion (and avoid immediate pre-cut because of anticipatory activity)\n",
    "            epochs_base = epochs.copy().crop(tmin=-0.2, tmax=-0.05)\n",
    "            inv_cache[subject] = make_inverse_from_baseline(epochs_base, fwd)\n",
    "\n",
    "        inv = inv_cache[subject]\n",
    "\n",
    "        print(f\">>>>>>>> {subject} {film}\")\n",
    "        stcs = extract_stcs(epochs, inv)\n",
    "        stcs_avg = average_stcs(stcs)\n",
    "        # save the averaged STC data in compressed format\n",
    "        np.savez_compressed(\n",
    "            output_path_stcs,\n",
    "            data=stcs_avg.data,\n",
    "            vertices=stcs_avg.vertices,\n",
    "            tmin=stcs_avg.tmin,\n",
    "            tstep=stcs_avg.tstep,\n",
    "            subject=stcs_avg.subject,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_source_localisation(\n",
    "        data_dir=DATA_DIR,\n",
    "        fs_subject=FS_SUBJECT,\n",
    "        fs_src_fname=FS_SRC_FNAME,\n",
    "        fs_bem_fname=FS_BEM_FNAME,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open stcs files and average across subjects for each film, then save the averaged stc data\n",
    "stcs_dir = Path(\"data/stcs\")\n",
    "\n",
    "cond_A_suffixes = (\"city_nl\", \"art_nl\")\n",
    "cond_B_suffixes = (\"city_l\",  \"art_l\")\n",
    "\n",
    "evoked_A = []\n",
    "evoked_B = []\n",
    "\n",
    "# collect subjects from filenames\n",
    "subjects = sorted({p.name.split(\"_\")[0] for p in stcs_dir.glob(\"*_stcs.npz\")})\n",
    "\n",
    "meta = None\n",
    "\n",
    "def _assert_same_meta(meta_ref, meta_new, label):\n",
    "    if not all(np.array_equal(v, v0) for v, v0 in zip(meta_new[\"vertices\"], meta_ref[\"vertices\"])):\n",
    "        raise ValueError(f\"Vertices mismatch for {label}.\")\n",
    "    if meta_new[\"tmin\"] != meta_ref[\"tmin\"]:\n",
    "        raise ValueError(f\"tmin mismatch for {label}: {meta_new['tmin']} != {meta_ref['tmin']}\")\n",
    "    if meta_new[\"tstep\"] != meta_ref[\"tstep\"]:\n",
    "        raise ValueError(f\"tstep mismatch for {label}: {meta_new['tstep']} != {meta_ref['tstep']}\")\n",
    "\n",
    "for sub in subjects:\n",
    "    # scrambled\n",
    "    files_A = [\n",
    "        stcs_dir / f\"{sub}_{c}_stcs.npz\"\n",
    "        for c in cond_A_suffixes\n",
    "        if (stcs_dir / f\"{sub}_{c}_stcs.npz\").exists()\n",
    "    ]\n",
    "\n",
    "    # linear\n",
    "    files_B = [\n",
    "        stcs_dir / f\"{sub}_{c}_stcs.npz\"\n",
    "        for c in cond_B_suffixes\n",
    "        if (stcs_dir / f\"{sub}_{c}_stcs.npz\").exists()\n",
    "    ]\n",
    "\n",
    "    if not files_A or not files_B:\n",
    "        print('skip incomplete subjects safely')\n",
    "        continue\n",
    "\n",
    "    # average within subject across films for each condition\n",
    "    sub_A = []\n",
    "    sub_B = []\n",
    "\n",
    "    for fp in files_A:\n",
    "        npz = np.load(fp, allow_pickle=True)\n",
    "        sub_A.append(npz[\"data\"])\n",
    "        meta_new = {\n",
    "            \"vertices\": npz[\"vertices\"],\n",
    "            \"tmin\": float(npz[\"tmin\"]),\n",
    "            \"tstep\": float(npz[\"tstep\"]),\n",
    "            \"subject\": str(npz[\"subject\"])\n",
    "        }\n",
    "        if meta is None:\n",
    "            meta = meta_new\n",
    "        else:\n",
    "            _assert_same_meta(meta, meta_new, f\"{fp.name}\")\n",
    "    for fp in files_B:\n",
    "        npz = np.load(fp, allow_pickle=True)\n",
    "        sub_B.append(npz[\"data\"])\n",
    "        meta_new = {\n",
    "            \"vertices\": npz[\"vertices\"],\n",
    "            \"tmin\": float(npz[\"tmin\"]),\n",
    "            \"tstep\": float(npz[\"tstep\"]),\n",
    "            \"subject\": str(npz[\"subject\"])\n",
    "        }\n",
    "        if meta is None:\n",
    "            meta = meta_new\n",
    "        else:\n",
    "            _assert_same_meta(meta, meta_new, f\"{fp.name}\")\n",
    "\n",
    "    evoked_A.append(np.mean(sub_A, axis=0))\n",
    "    evoked_B.append(np.mean(sub_B, axis=0))\n",
    "\n",
    "evoked_A = np.stack(evoked_A)\n",
    "evoked_B = np.stack(evoked_B)\n",
    "\n",
    "GA_A = evoked_A.mean(0)\n",
    "GA_B = evoked_B.mean(0)\n",
    "\n",
    "if meta is None:\n",
    "    raise RuntimeError(\"No subjects with complete conditions found.\")\n",
    "\n",
    "GA_A_stc = mne.SourceEstimate(\n",
    "    GA_A,\n",
    "    vertices=meta[\"vertices\"].tolist(),\n",
    "    tmin=meta[\"tmin\"],\n",
    "    tstep=meta[\"tstep\"],\n",
    "    subject=meta[\"subject\"],\n",
    ")\n",
    "\n",
    "GA_B_stc = mne.SourceEstimate(\n",
    "    GA_B,\n",
    "    vertices=meta[\"vertices\"].tolist(),\n",
    "    tmin=meta[\"tmin\"],\n",
    "    tstep=meta[\"tstep\"],\n",
    "    subject=meta[\"subject\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f108a7",
   "metadata": {},
   "source": [
    "## Visualusation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b0e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in [-0.2, 0.0, 0.1, 0.2, 0.4, 0.8]:\n",
    "t = 0.8\n",
    "stc_one = GA_B_stc.copy().crop(t, t)\n",
    "\n",
    "brain = stc_one.plot(\n",
    "    subject=\"fsaverage\",\n",
    "    subjects_dir=SUBJECTS_DIR,\n",
    "    hemi=\"both\",\n",
    "    views=\"lateral\",\n",
    "    colorbar=True,\n",
    "    time_viewer=True,\n",
    "    backend=\"notebook\" # for faster html saving\n",
    "    )\n",
    "\n",
    "plotter = brain._renderer.plotter\n",
    "\n",
    "out_dir = Path(\"data/stc_vis\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_html = out_dir / f\"linear_{int(t*1000)}.html\"\n",
    "\n",
    "if hasattr(brain, \"save_html\"):\n",
    "    brain.save_html(out_html, time_viewer=True)\n",
    "else:\n",
    "    plotter.export_html(str(out_html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pixi(MovieEEG)",
   "language": "python",
   "name": "movieeeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
